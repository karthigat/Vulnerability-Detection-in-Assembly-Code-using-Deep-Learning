{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "sqQtulHsik0x",
        "outputId": "a743580c-28da-49b5-88ff-de2733a74487"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9ee4dc52-a4c1-4b9a-9b7b-edfef78b7490\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9ee4dc52-a4c1-4b9a-9b7b-edfef78b7490\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving transformer.ep19 to transformer.ep19\n",
            "Saving vocab to vocab\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFmIvxr8iklV",
        "outputId": "5d57a732-66f0-45b4-c6e2-3d005f83b2f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bert-pytorch\n",
            "  Downloading bert_pytorch-0.0.1a4-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from bert-pytorch) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from bert-pytorch) (1.21.6)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from bert-pytorch) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=0.4.0->bert-pytorch) (4.1.1)\n",
            "Installing collected packages: bert-pytorch\n",
            "Successfully installed bert-pytorch-0.0.1a4\n"
          ]
        }
      ],
      "source": [
        "!pip install bert-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S895XK7diicE",
        "outputId": "f8d58b7e-66d9-4b5a-f42a-f35774b3b5b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgE_ggtaj3ZN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# torch.cuda.is_available()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjK70vLYp9d8",
        "outputId": "0b6fc802-a2c3-485f-89fe-f1265d9ee78a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pickle5\n",
            "  Downloading pickle5-0.0.11.tar.gz (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 4.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pickle5\n",
            "  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pickle5: filename=pickle5-0.0.11-cp38-cp38-linux_x86_64.whl size=236288 sha256=afc4aa39cc8a83badd1afa357258dc397b451e550edfe4a5394112ea9acfeca9\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/d4/61/dbd8edd1a0d656be7b4267c85db3b61951eb60016a0154a122\n",
            "Successfully built pickle5\n",
            "Installing collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.11\n"
          ]
        }
      ],
      "source": [
        "!pip install pickle5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c27CVrsp3GU",
        "outputId": "e9607dfb-02a9-4981-c2c9-eb673fc726a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "4Azb3xrKRvul",
        "outputId": "6ca79717-6e7f-4476-80b9-32c6f13cb359"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBsoeEfAR3XR"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getFlawCode():\n",
        "  \"\"\"\n",
        "   get malicious.pkl file and convert it into vectors\n",
        "   add it a dictionary and label it as '0'\n",
        "  \"\"\"\n",
        "  source_files = \"malicious.pkl\"\n",
        "  open_file = open(source_files, \"rb\")\n",
        "  loaded_list = pickle.load(open_file)\n",
        "  open_file.close()\n",
        "  count = 0\n",
        "  for i in loaded_list:\n",
        "    count = count+len(i)\n",
        "    embeddings = palmtree.encode(i)\n",
        "    dict_embeddings_flaw = {\"vectors\":embeddings, \"val\":0}\n",
        "    append_vectors_flaw.append(dict_embeddings_flaw) \n",
        "  return append_vectors_flaw"
      ],
      "metadata": {
        "id": "mJbdL0Cy4s1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getFlawlessCode():\n",
        "  \"\"\"\n",
        "   get instruction tokens from non_malicious.pkl and convert it to vectors\n",
        "   label it as '1'\n",
        "  \"\"\"\n",
        "  source_files = \"non_malicious.pkl\"\n",
        "  open_file = open(source_files, \"rb\")\n",
        "  loaded_list = pickle.load(open_file)\n",
        "  open_file.close()\n",
        "  count=0\n",
        "  for i in loaded_list:\n",
        "    if len(i) != 0:\n",
        "      count = count+len(i)\n",
        "      embeddings = palmtree.encode(i)\n",
        "    dict_embeddings_flaw = {\"vectors\":embeddings, \"val\":1}\n",
        "    append_vectors_flawless.append(dict_embeddings_flaw)\n",
        "  return append_vectors_flawless"
      ],
      "metadata": {
        "id": "PU4hhX0n48ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge(flaw, flawless):\n",
        "  \"\"\"\n",
        "   merge flaw and flawless code\n",
        "  \"\"\"\n",
        "  df_flaw = pandas.DataFrame(flaw)\n",
        "  df_flawless = pandas.DataFrame(flawless)\n",
        "  append_flaw = df_flaw.append(df_flawless)\n",
        "  return append_flaw"
      ],
      "metadata": {
        "id": "jbd0FEVT5MHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def padding(shuffled):\n",
        "  \"\"\"\n",
        "   pad vectors before fedding it to lstm network\n",
        "  \"\"\"\n",
        "  check = shuffled.iloc[:, 0].values #train\n",
        "  row_list = list(check[i].shape[0] for i in range(0, len(check))) #train\n",
        "  max_length = max(row_list)\n",
        "  list_stack = []\n",
        "  for j in check:\n",
        "    if len(j) <= max_length:\n",
        "      n = max_length - len(j)\n",
        "      rearrange= np.vstack((j,np.zeros((n,128))))\n",
        "      list_stack.append(rearrange)\n",
        "  stack = np.array(list_stack)\n",
        "  return stack"
      ],
      "metadata": {
        "id": "HWgsSdJ45QwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split(pad_embedding):\n",
        "  \"\"\"\n",
        "   split training and validation dataset\n",
        "  \"\"\"\n",
        "  \n",
        "  vectors = pad_embedding\n",
        "  labels = shuffled.iloc[:, 1].values\n",
        "  \n",
        "  positive_idxs = np.where(labels == 1)[0]\n",
        "  negative_idxs = np.where(labels == 0)[0]\n",
        "  k=4\n",
        "  res = positive_idxs[: len(positive_idxs) - k]\n",
        "  undersampled_negative_idxs = np.random.choice(negative_idxs, len(res), replace=False)\n",
        "  resampled_idxs = np.concatenate([positive_idxs, undersampled_negative_idxs])\n",
        "  X_train, X_test, y_train, y_test = train_test_split(vectors, labels,\n",
        "                                                          random_state = 1,test_size=0.2, stratify=labels, shuffle=True)\n",
        " \n",
        "# X_train, X_test, y_train, y_test = train_test_split(vectors[resampled_idxs], labels[resampled_idxs],\n",
        "#                                                         random_state = 1,test_size=0.3, stratify=labels[resampled_idxs])\n",
        "  return X_train, X_test, y_train, y_test, labels"
      ],
      "metadata": {
        "id": "mFByLckN5W6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, xtrain, ytrain):\n",
        "  \"\"\"\n",
        "   train lstm netwrok and save the model\n",
        "  \"\"\"\n",
        "  history = model.fit(X_train, y_train, batch_size=batch_size, epochs=30, callbacks=callback, class_weight=class_weight)\n",
        "  draw_train_history(history)\n",
        "  model.save_weights(\"lstm_model.h5\")"
      ],
      "metadata": {
        "id": "MagnPKWk5cVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_train_history(history):\n",
        "    \"\"\"\n",
        "     plot training history\n",
        "    \"\"\"\n",
        "    plt.figure(1)\n",
        "    plt.subplot(211)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train'])\n",
        "    plt.subplot(212)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train'])\n",
        "    plt.savefig('loss_accuracy.png')\n",
        "    plt.show()\n",
        "   "
      ],
      "metadata": {
        "id": "YBeid1Eu5iND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEPNNaUhieh2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from config import *\n",
        "from torch import nn\n",
        "from scipy.ndimage.filters import gaussian_filter1d\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "import numpy as np\n",
        "import eval_utils as utils\n",
        "import glob\n",
        "import re\n",
        "import pandas\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from sklearn.utils import compute_class_weight\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Bidirectional, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import pickle5 as pickle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "palmtree = utils.UsableTransformer(model_path=\"/content/transformer.ep19\", vocab_path=\"/content/vocab\")\n",
        "batch_size = 4\n",
        "name = \"trained\"\n",
        "\n",
        "# example\n",
        "#text = [\"mov rbp rdi\", \n",
        "        # \"mov ebx 0x1\", \n",
        "        # \"mov rdx rbx\", \n",
        "        # \"call memcpy\", \n",
        "        # \"mov [ rcx + rbx ] 0x0\", \n",
        "        # \"mov rcx rax\", \n",
        "        # \"mov rcx ray\", \n",
        "        # \"mov [ rax ] 0x2e\"]\n",
        "\n",
        "dict_list_emb = []\n",
        "append_vectors_flaw = []\n",
        "append_vectors_flaw_backup = []\n",
        "add_lines = []\n",
        "append_vectors_flawless = []\n",
        "flaw = getFlawCode()\n",
        "\n",
        "flawless = getFlawlessCode()\n",
        "flawbackup = getFlawCodeBackup()\n",
        "merge_df = merge(flaw, flawless, flawbackup)\n",
        "shuffled = shuffle(merge_df)\n",
        "pad_embedding = padding(shuffled)\n",
        "X_train, X_test, y_train, y_test, labels = split(pad_embedding)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(vectors, labels,\n",
        "                                                          # random_state = 1,test_size=0.2, stratify=labels, shuffle=True)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
        "                                                          random_state = 1,test_size=0.2, stratify=y_train, shuffle=True)\n",
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_val.shape)\n",
        "X_train = X_train\n",
        "X_test = X_test\n",
        "X_val = X_val\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "name = name\n",
        "batch_size = batch_size\n",
        "class_weight = compute_class_weight(class_weight='balanced', classes=[0, 1], y=labels)\n",
        "class_weight = {i : class_weight[i] for i in range(2)}\n",
        "\n",
        "# train LSTM netwrok\n",
        "model = Sequential()\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', min_delta = 0.005, patience=5)\n",
        "model.add(Bidirectional(LSTM(100)))\n",
        "model.add(Dense(2, activation='sigmoid')) #softmax\n",
        "adamax = Adamax(lr=0.002)\n",
        "model.compile(adamax, 'categorical_crossentropy', metrics=['accuracy'])\n",
        "model = model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hd4H2OKAeP78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "c36b88ea-8e63-4d0a-dae2-7aa3a399eb6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "113/113 [==============================] - 30s 231ms/step - loss: 0.1853 - accuracy: 0.9178\n",
            "Epoch 2/30\n",
            "113/113 [==============================] - 26s 230ms/step - loss: 0.0398 - accuracy: 0.9867\n",
            "Epoch 3/30\n",
            "113/113 [==============================] - 26s 231ms/step - loss: 0.0191 - accuracy: 0.9956\n",
            "Epoch 4/30\n",
            "113/113 [==============================] - 26s 231ms/step - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "113/113 [==============================] - 26s 231ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "113/113 [==============================] - 26s 231ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "113/113 [==============================] - 26s 231ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "113/113 [==============================] - 26s 231ms/step - loss: 0.0019 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20284.34765625\n"
          ]
        }
      ],
      "source": [
        "import os, psutil, time\n",
        "start = time.time()\n",
        "train(model, X_train, y_train)\n",
        "print(psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2)\n",
        "time.sleep(1)\n",
        "end = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(end-start)"
      ],
      "metadata": {
        "id": "1UP-5bdCmATC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQEvVD0riCbR"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJfjCAE1fRLI"
      },
      "outputs": [],
      "source": [
        "def decision(pre, test):\n",
        "    \"\"\"\n",
        "     evaluation - confusion matrix, tp, tn, fp, fn, recall, precision, F1\n",
        "    \"\"\"\n",
        "    cout=0\n",
        "    yes = 0\n",
        "    print(test)\n",
        "    print(pre)\n",
        "    tn, fp, fn, tp = confusion_matrix(test, pre, labels=[0, 1]).ravel()\n",
        "    print(tn, fp, fn, tp)\n",
        "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
        "    print(\"Accuracy is..\",(accuracy*100))\n",
        "    print('False positive rate is...', fp / (fp + tn))\n",
        "    print('False negative rate is...', fn / (fn + tp))\n",
        "    recall = tp / (tp + fn)\n",
        "    print('True positive rate is...', recall)\n",
        "    precision = tp / (tp + fp)\n",
        "    print('Precision is...', precision)\n",
        "    print('F1 score is...', (2 * precision * recall) / (precision + recall))\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_ARt0Pj8l_j"
      },
      "outputs": [],
      "source": [
        "### test ###\n",
        "def test():\n",
        "  \"\"\"\n",
        "    test model on few samples\n",
        "  \"\"\"\n",
        "  source_files_good = \"non_malicious_test.pkl\"\n",
        "  open_file_good = open(source_files_good, \"rb\")\n",
        "  loaded_list_good = pickle.load(open_file_good)\n",
        "  open_file_good.close()\n",
        "  for i in loaded_list_good:\n",
        "    if len(i) != 0:\n",
        "      embeddings_non_malicious = palmtree.encode(i)\n",
        "  source_files_bad = \"malicious_test.pkl\"\n",
        "  open_file_bad = open(source_files_bad, \"rb\")\n",
        "  loaded_list_bad = pickle.load(open_file_bad)\n",
        "  open_file_bad.close()\n",
        "  for i in loaded_list_bad:\n",
        "    if len(i) != 0:\n",
        "      embeddings_malicious = palmtree.encode(i)\n",
        "  flaw_flawless = merge(embeddings_non_malicious, embeddings_malicious)\n",
        "  to_ndarray = shuffled.to_numpy()\n",
        "  return to_ndarray   # X_train, X_test, y_train, y_test, labels  = split(shuffled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4V9hvFHaU_L"
      },
      "outputs": [],
      "source": [
        "model.load_weights(\"lstm_model.h5\")\n",
        "\n",
        "#validation\n",
        "values = model.evaluate(X_val, y_val, batch_size=4)\n",
        "print(\"Accuracy is...\", values[1])\n",
        "\n",
        "# predict \n",
        "predictions = (model.predict(X_test, batch_size=4)).round()\n",
        "pre = np.argmax(predictions, axis=1)\n",
        "test = np.argmax(y_test, axis=1)\n",
        "decision(pre, test)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}